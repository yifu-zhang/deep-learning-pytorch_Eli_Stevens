{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57423370",
   "metadata": {},
   "source": [
    "## 4.1 Working with images\n",
    "Loading an image file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef816f58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(720, 1280, 3)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import imageio\n",
    "\n",
    "img_arr = imageio.imread('bobby.jpg')\n",
    "img_arr.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc313a7",
   "metadata": {},
   "source": [
    "Any library that outputs a NumPy array will suffice to obtain a Pytorch tensor. Pytorch modules dealing with image data require tensors to be laid out as C\\*H\\*W: channels height and width, respectively.\n",
    "\n",
    "As a slightly more efficient alternative to using $stack$ to build up the tensor, we can pre-allocate a tensor of appropriate size and fill it with images loaded from a directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a20590d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "batch_size = 3\n",
    "batch = torch.zeros(batch_size, 3, 256, 256, dtype = torch.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41eeda8",
   "metadata": {},
   "source": [
    "This indicates that our batch will consist of three RGB images 256 pixels in height and 256 pixels in width.\n",
    "\n",
    "We can now load all PNG images from an input directory and store them in the tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f74118ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "data_dir = 'image-cats/'\n",
    "filenames = [name for name in os.listdir(data_dir)\n",
    "             if os.path.splitext(name)[-1] == '.png']\n",
    "for i, filename in enumerate(filenames):\n",
    "    img_arr = imageio.imread(os.path.join(data_dir, filename))\n",
    "    img_t = torch.from_numpy(img_arr)\n",
    "    img_t = img_t.permute(2, 0, 1) # change the order of dimension\n",
    "    img_t = img_t[:3]\n",
    "    batch[i] = img_t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29cf58b3",
   "metadata": {},
   "source": [
    "### 4.1.4 Normalizing the data\n",
    "Neural networks exhibit the best performance when the input data ranges roughly from 0 to 1, or from -1 to 1. So a typical thing we'll want to do is cast a tensor to floating-point and normalize the values of the pixels. Normalizationg is tricker,as it depends on what range of the input we decide should lie between 0 and 1.\n",
    "\n",
    "## 4.3 Representing tabular data\n",
    "We are going to assume there's no meaning to the order in which samples appear in the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a66f389",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7.  ,  0.27,  0.36, ...,  0.45,  8.8 ,  6.  ],\n",
       "       [ 6.3 ,  0.3 ,  0.34, ...,  0.49,  9.5 ,  6.  ],\n",
       "       [ 8.1 ,  0.28,  0.4 , ...,  0.44, 10.1 ,  6.  ],\n",
       "       ...,\n",
       "       [ 6.5 ,  0.24,  0.19, ...,  0.46,  9.4 ,  6.  ],\n",
       "       [ 5.5 ,  0.29,  0.3 , ...,  0.38, 12.8 ,  7.  ],\n",
       "       [ 6.  ,  0.21,  0.38, ...,  0.32, 11.8 ,  6.  ]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "wine_path = 'winequality-white.csv'\n",
    "wineq_numpy = np.loadtxt(wine_path, dtype = np.float32, delimiter=\";\", skiprows=1)\n",
    "wineq_numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eaf5b8a",
   "metadata": {},
   "source": [
    "Here, we just prescribe what the type of the 2D array should be, the delimiter used to seperate values in each row, and the fact that the first line should not be read since it contains the column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "303b606b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4898, 12),\n",
       " ['fixed acidity',\n",
       "  'volatile acidity',\n",
       "  'citric acid',\n",
       "  'residual sugar',\n",
       "  'chlorides',\n",
       "  'free sulfur dioxide',\n",
       "  'total sulfur dioxide',\n",
       "  'density',\n",
       "  'pH',\n",
       "  'sulphates',\n",
       "  'alcohol',\n",
       "  'quality'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_list = next(csv.reader(open(wine_path), delimiter=';'))\n",
    "wineq_numpy.shape, col_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6032d2b0",
   "metadata": {},
   "source": [
    "Proceed to convert the NumPy array to a Pytorch tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb3889a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4898, 12]), torch.float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wineq = torch.from_numpy(wineq_numpy)\n",
    "wineq.shape, wineq.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2418e4",
   "metadata": {},
   "source": [
    "At this point, we have a floating-point torch.Tensor containing all the columns, including the last, which refers to the quality score.\n",
    "\n",
    "### 4.3.3 Representing scores\n",
    "We could treat the scores as a continuous variable, keep it as a real number, and perform a regression task, or treat it as a label and try to guess the label from chemical analysis in a classification task. In both approaches, we will typically remove the score from the tensor of input data and keep it in a separate tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "50ff0d55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 7.0000,  0.2700,  0.3600,  ...,  3.0000,  0.4500,  8.8000],\n",
       "         [ 6.3000,  0.3000,  0.3400,  ...,  3.3000,  0.4900,  9.5000],\n",
       "         [ 8.1000,  0.2800,  0.4000,  ...,  3.2600,  0.4400, 10.1000],\n",
       "         ...,\n",
       "         [ 6.5000,  0.2400,  0.1900,  ...,  2.9900,  0.4600,  9.4000],\n",
       "         [ 5.5000,  0.2900,  0.3000,  ...,  3.3400,  0.3800, 12.8000],\n",
       "         [ 6.0000,  0.2100,  0.3800,  ...,  3.2600,  0.3200, 11.8000]]),\n",
       " torch.Size([4898, 11]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = wineq[:, :-1]\n",
    "data, data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "93dc307e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([6, 6, 6,  ..., 6, 7, 6]), torch.Size([4898]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = wineq[:, -1].long()\n",
    "target, target.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eac5ef5",
   "metadata": {},
   "source": [
    "We can achieve one-hot encoding using the scatter_ method, which fills the tensor with values from a source tensor along the indices provided as arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "21f7ead4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_onehot = torch.zeros(target.shape[0], 10)\n",
    "target_onehot.scatter_(1, target.unsqueeze(1), 1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5f53cf",
   "metadata": {},
   "source": [
    "The arguments for scatter_ are as follows:\n",
    "1. The dimension along which the following two arguments are specified\n",
    "2. A column tensor indicating the indices of the elements to scatter\n",
    "3. A tensor containing the elements to scatter or a single scalar to scatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7dbb4c20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[6],\n",
       "        [6],\n",
       "        [6],\n",
       "        ...,\n",
       "        [6],\n",
       "        [7],\n",
       "        [6]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_unsqueezed = target.unsqueeze(1)\n",
    "target_unsqueezed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc51095",
   "metadata": {},
   "source": [
    "The call to $unsqueeze$ adds a $singleton$ dimension, from 1D tensor of 4898 elements to a 2D tensor of size (4898\\*1), without changing its content-no extra elements are added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "84369959",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(6), tensor(6))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target[0], target_unsqueezed[0,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78b02af",
   "metadata": {},
   "source": [
    "Let's go back to our $data$ tensor, containing 11 variables associated with the chemical analysis. We can use the funcitons in the PyTorch API to manipulate our data in tensor form. Let's first obtain the mean and sd for each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1ecab792",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6.8548e+00, 2.7824e-01, 3.3419e-01, 6.3914e+00, 4.5772e-02, 3.5308e+01,\n",
       "        1.3836e+02, 9.9403e-01, 3.1883e+00, 4.8985e-01, 1.0514e+01])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_mean = torch.mean(data, dim=0)\n",
    "data_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2dbd1ae4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7.1211e-01, 1.0160e-02, 1.4646e-02, 2.5726e+01, 4.7733e-04, 2.8924e+02,\n",
       "        1.8061e+03, 8.9455e-06, 2.2801e-02, 1.3025e-02, 1.5144e+00])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_var = torch.var(data, dim=0)\n",
    "data_var"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98beed4f",
   "metadata": {},
   "source": [
    "In this case, dim=0 indicates that the reduction is performed along dimension 0. At this point, we can normalize the data by subtracting the mean and dividing by the sd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "574349e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.7208e-01, -8.1761e-02,  2.1326e-01,  ..., -1.2468e+00,\n",
       "         -3.4915e-01, -1.3930e+00],\n",
       "        [-6.5743e-01,  2.1587e-01,  4.7996e-02,  ...,  7.3995e-01,\n",
       "          1.3422e-03, -8.2419e-01],\n",
       "        [ 1.4756e+00,  1.7450e-02,  5.4378e-01,  ...,  4.7505e-01,\n",
       "         -4.3677e-01, -3.3663e-01],\n",
       "        ...,\n",
       "        [-4.2043e-01, -3.7940e-01, -1.1915e+00,  ..., -1.3130e+00,\n",
       "         -2.6153e-01, -9.0545e-01],\n",
       "        [-1.6054e+00,  1.1666e-01, -2.8253e-01,  ...,  1.0049e+00,\n",
       "         -9.6251e-01,  1.8574e+00],\n",
       "        [-1.0129e+00, -6.7703e-01,  3.7852e-01,  ...,  4.7505e-01,\n",
       "         -1.4882e+00,  1.0448e+00]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_normalized = (data-data_mean)/torch.sqrt(data_var)\n",
    "data_normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85b8fa9",
   "metadata": {},
   "source": [
    "### 4.3.6 Finding thresholds\n",
    "Next, we're going to determine which rows in $target$ correspond to a score less than or equal to 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b5305c92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4898]), torch.bool, tensor(20))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_indexes = target <= 3\n",
    "bad_indexes.shape, bad_indexes.dtype, bad_indexes.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f525cdce",
   "metadata": {},
   "source": [
    "The bad_indexes tensor has the same shape as $target$, with values of False or True depending on the outcome of the comparison between our threshold and each element in the orginal $target$ tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4af864da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 11])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_data = data[bad_indexes]\n",
    "bad_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6c0ea9",
   "metadata": {},
   "source": [
    "We can start to get information about wines grouped into good, middling, and bad categories. Let's take the .mean() of each column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "12c6c5a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0 fixed acidity          7.60   6.89   6.73\n",
      " 1 volatile acidity       0.33   0.28   0.27\n",
      " 2 citric acid            0.34   0.34   0.33\n",
      " 3 residual sugar         6.39   6.71   5.26\n",
      " 4 chlorides              0.05   0.05   0.04\n",
      " 5 free sulfur dioxide   53.33  35.42  34.55\n",
      " 6 total sulfur dioxide 170.60 141.83 125.25\n",
      " 7 density                0.99   0.99   0.99\n",
      " 8 pH                     3.19   3.18   3.22\n",
      " 9 sulphates              0.47   0.49   0.50\n",
      "10 alcohol               10.34  10.26  11.42\n"
     ]
    }
   ],
   "source": [
    "bad_data = data[target <= 3]\n",
    "mid_data = data[(target > 3) & (target < 7)]\n",
    "good_data = data[target >= 7]\n",
    "\n",
    "bad_mean = torch.mean(bad_data, dim = 0)\n",
    "mid_mean = torch.mean(mid_data, dim = 0)\n",
    "good_mean = torch.mean(good_data, dim = 0)\n",
    "\n",
    "for i, args in enumerate(zip(col_list, bad_mean, mid_mean, good_mean)):\n",
    "    print('{:2} {:20} {:6.2f} {:6.2f} {:6.2f}'.format(i, *args))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b5de0f",
   "metadata": {},
   "source": [
    "We could use a threshold on total sulfur dioxide as a crude criterion for discriminating good wines from bad ones. Let's get the indexes where the total sulfur dioxide column is below the midpoint we calcualted earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "87fa6a20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4898]), torch.bool, tensor(2727))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_sulfur_threshold = 141.83\n",
    "total_sulfur_data = data[:, 6]\n",
    "predicted_indexes = torch.lt(total_sulfur_data, total_sulfur_threshold)\n",
    "\n",
    "predicted_indexes.shape, predicted_indexes.dtype, predicted_indexes.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157b15c7",
   "metadata": {},
   "source": [
    "Next, we'll need to get the indexes of the actually good wines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8bf4cd88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4898]), torch.bool, tensor(3258))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual_indexes = target > 5\n",
    "actual_indexes.shape, actual_indexes.dtype, actual_indexes.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4817726d",
   "metadata": {},
   "source": [
    "We'll perform a logical \"and\" between our prediction indexes and the actual good indexes and use that interaction of wines-in-agreement to determine how well we did:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "85245d8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2018, 0.74000733406674, 0.6193984039287906)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_matches = torch.sum(actual_indexes & predicted_indexes).item()\n",
    "n_predicted = torch.sum(predicted_indexes).item()\n",
    "n_actual = torch.sum(actual_indexes).item()\n",
    "\n",
    "n_matches, n_matches / n_predicted, n_matches / n_actual"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3013ad",
   "metadata": {},
   "source": [
    "We got around 2000 wines right! Since we predicted 2700 wines, this gives us a 74% chance that if we predict a wine to be high quality, it actually is. Unfortunately, there are 3200 good wines, and we only identified 61% of them.\n",
    "## 4.4 Working with timeseries\n",
    "4.4.1 Adding a time dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b0e7bd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([17520, 17])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "bikes_numpy = np.loadtxt('hour-fixed.csv', dtype=np.float32,\n",
    "                        delimiter=\",\", skiprows=1,\n",
    "                        converters={1: lambda x: float(x[8:10])})\n",
    "bikes = torch.from_numpy(bikes_numpy)\n",
    "bikes.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64101c44",
   "metadata": {},
   "source": [
    "instant, day, season, year, month, hour, holiday, weekday, workingday, weathersit, temp, atemp, hum, windspeed, casual, registered, count of rental bikes: cnt.\n",
    "\n",
    "The existence of an ordering gives us the opportunity to exploit causal relationships across time. We're going to focus on learning how to turn our bike-sharing dataset into something that our nn will be able to ingest in fixed-size chunks.\n",
    "### 4.4.2 Shaping the data by time period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d66a5901",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17, 1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bikes.stride()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc145c3",
   "metadata": {},
   "source": [
    "That's 17520 hours, 17 columns. Now let's reshape the data to have 3 axes - day, hour, and then our 17 columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd87d037",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([730, 24, 17]), (408, 17, 1))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_bikes = bikes.view(-1, 24, bikes.shape[1])\n",
    "daily_bikes.shape, daily_bikes.stride()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a617a2",
   "metadata": {},
   "source": [
    "Our call to view requires us to provide the new shape for the returned tensor. We use -1 as a placeholder for \"however many indexes are left, given the other dimensions and the original number of elements\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5fcaa1dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([730, 17, 24]), (408, 1, 17))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_bikes = daily_bikes.transpose(1, 2)\n",
    "daily_bikes.shape, daily_bikes.stride()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37cc1c31",
   "metadata": {},
   "source": [
    "We now have N sequences of L hours in a day, for C channels. To get to our desired N × C × L ordering, we have transposed the tensor.\n",
    "### 4.3.3 Ready for training\n",
    "The 'weather situation' variable is ordinal. It has four levels: 1 for good weather, and 4 for really bad. We could treat this variable as categorical, with levels interpreted as labels, or as a continuous variable.\n",
    "## 4.5 Representing text"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
